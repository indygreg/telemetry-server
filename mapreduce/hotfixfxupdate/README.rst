Firefox Update Hotfix Analysis
==============================

This directory contains map reduce jobs and support scripts for making
sense of the Firefox update hotfix data.

Environment Setup
=================

Create a virtualenv:

   virtualenv venv
   source venv/bin/activate

Install the AWS command line interface:

   pip install awscli

Install the telemetry-server Python package:

   cd /path/to/telemetry-server
   python setup.py develop

Obtain S3 data
==============

If you would like a local copy of all the hotfix data, you can grab it
from S3.

The easiest way to do this is to install the AWS CLI from
https://aws.amazon.com/cli/.

Once you have it configured, you can synchronize the data to the local
directory by running:

    aws s3 sync s3://hotfix-published-v1 .

This will likely transfer gigabytes of data from S3. You have been
warned.

Deduplication
=============

The data set on the server may contain multiple entries for each record.
The first step of analysis is to remove duplicates.

This is faciliated by running the ``dedupe.py`` job.

The output of this job lists all records that are earlier versions of
records and should be discarded. The filename of the output **must** be
``oldrecords`` and only 1 reducer must be used.

Here is an example of how to run this job::

   python -mmapreduce.job -m 8 -r 1 -l -d data -w work -o oldrecords
   -f /path/to/telemetry-server/mapreduce/hotfixupdate/filter.json
   /path/to/telemetry-server/mapreduce/hotfixupdate/dedupe.py

This assumes the data from S3 is available in a ``data`` directory.

Stats Job
=========

The ``stats.py`` job outputs a lot of counts and interesting metrics for
the data. It's probably the first and only job you want to run.

   python -mmapreduce.job -m 8 -r 8 -c 8 -l -d data -w work -o stats
   -f /path/to/telemetry-server/mapreduce/filter.json
   /path/to/telemetry-server/mapreduce/hotfixupdate/stats.py

Displaying Stats
================

The generated file from ``stats.py`` isn't very human readable. To fix this,
we have a couple of scripts.

``normalize-stats.py`` is a simple script to print a normalized version of
the ``stats.py`` output file. All it really does is parse the data and add
tabs.

``convert-to-percent.py`` is slightly more interesting. It groups all the
stats together and computes percentages of each item in its group. It also
displays cumulative and cumulative remaining values. It's probably what you
want to use to view data generated by ``stats.py``.

For both scripts, pass the output file from the ``stats.py`` job as an
argument.
